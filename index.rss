<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/"><channel><title>Boletim diário de segurança</title><link>https://boletimsec.com.br/boletim-diario-ciberseguranca/</link><description>NGSX RSS Feed</description><language>pt-BR</language><generator>rfeed v1.1.1</generator><docs>https://github.com/svpino/rfeed/blob/master/README.md</docs><item><title>* Malware GOVERSHELL evolui e transforma IA em aliada de ataques cibernéticos.</title><link>https://boletimsec.com.br/boletim-diario-ciberseguranca/</link><description>Pesquisadores de cibersegurança identificaram uma nova e sofisticada campanha de espionagem digital ligada a hackers chineses, que utilizam inteligência artificial para aprimorar ataques direcionados. O grupo, identificado como UTA0388, é o responsável pelo desenvolvimento do GOVERSHELL, um malware avançado escrito em linguagem Go e usado para infiltrar redes corporativas e governamentais em diferentes países. A campanha teve início com e-mails de phishing personalizados, criados com apoio de ferramentas de IA generativa como o ChatGPT. As mensagens imitavam convites de universidades, instituições de pesquisa e agências internacionais, induzindo as vítimas a baixar arquivos compactados (ZIP ou RAR) hospedados em serviços legítimos como OneDrive, Netlify e Sync. Esses arquivos continham o malware GOVERSHELL. Após ser executado, o GOVERSHELL utiliza a técnica de DLL side-loading, explorando bibliotecas legítimas do Windows para executar código malicioso de forma silenciosa. O malware age como um backdoor de espionagem, capaz de coletar informações, executar comandos remotos e estabelecer comunicação constante com servidores controlados pelos invasores. O GOVERSHELL é uma evolução do malware HealthKick, identificado no início de 2025. Desde então, os pesquisadores descobriram cinco variantes do código, cada uma mais sofisticada. A versão mais recente, chamada Beacon, ajusta automaticamente o intervalo de comunicação com o servidor e imita o tráfego de aplicativos legítimos, tornando a detecção muito mais difícil. Além das melhorias técnicas, o uso de IA generativa marca um novo patamar de automação nos ataques. De acordo com os analistas, o grupo criou personas falsas e mensagens multilíngues com auxílio do ChatGPT, gerando comunicações em inglês, chinês e japonês com alto grau de realismo. A OpenAI confirmou que contas fraudulentas foram suspensas, mas reconheceu que os invasores buscaram automatizar todo o processo de phishing.</description><guid isPermaLink="true">https://boletimsec.com.br/boletim-diario-ciberseguranca/</guid></item><item><title>* Falha no Grafana é usada em ataques a sistemas corporativos.</title><link>https://boletimsec.com.br/boletim-diario-ciberseguranca/</link><description>A vulnerabilidade CVE-2021-43798, identificada no Grafana, ferramenta popular de monitoramento e observabilidade de sistemas, voltou a ser explorada ativamente por grupos cibercriminosos em ataques contra empresas em todo o mundo. O alerta foi emitido pela Agência de Segurança Cibernética e de Infraestrutura dos Estados Unidos (CISA), que incluiu o problema em seu catálogo oficial de vulnerabilidades exploradas. A falha, afeta as versões 8.0.0-beta1 até 8.3.0 do Grafana e permite que invasores acessem arquivos internos do servidor sem autenticação. O ataque é possível por meio da manipulação da URL de plug-ins da ferramenta, explorando uma brecha de path traversal que concede acesso não autorizado a diretórios e dados sensíveis. De acordo com a CISA, a vulnerabilidade tem sido usada em campanhas recentes para obter credenciais administrativas, ler arquivos de configuração e roubar informações de logs. O acesso indevido também pode permitir movimentação lateral dentro da rede e comprometimento de outros sistemas integrados. A agência informou que todas as instalações autogerenciadas do Grafana devem ser atualizadas imediatamente para as versões corrigidas 8.0.7, 8.1.8, 8.2.7 ou 8.3.1. O serviço Grafana Cloud, mantido pela própria empresa, não é afetado. Órgãos federais dos Estados Unidos receberam prazo até 30 de outubro de 2025 para aplicar as correções, conforme determinação da diretriz operacional BOD 22-01. Especialistas alertam que a falha é amplamente explorada por grupos de ransomware e operadores de botnets, que buscam sistemas de monitoramento expostos à internet. Em muitos casos, os painéis do Grafana contêm informações estratégicas sobre infraestrutura, senhas e credenciais de serviços em nuvem, tornando o alvo valioso para espionagem corporativa.</description><guid isPermaLink="true">https://boletimsec.com.br/boletim-diario-ciberseguranca/</guid></item><item><title>* Ferramentas de IA se tornam novo risco de exposição de dados sensíveis.</title><link>https://boletimsec.com.br/boletim-diario-ciberseguranca/</link><description>O uso crescente de ferramentas de inteligência artificial generativa, como ChatGPT, Copilot e Gemini, tem criado uma nova e preocupante superfície de risco para empresas de todo o mundo. Um relatório recente revelou que 77% dos funcionários compartilham informações corporativas em plataformas de IA, muitas vezes sem autorização ou proteção adequada. O estudo mostra que 18% dos usuários corporativos colam dados diretamente em chatbots de IA, e cerca da metade desses envios contém informações confidenciais, como planilhas financeiras, códigos-fonte, credenciais, contratos e relatórios internos. Em muitos casos, esses dados são transmitidos por contas pessoais, fora do alcance das políticas de segurança e monitoramento da empresa. O fenômeno, conhecido como Shadow AI, ocorre quando funcionários usam ferramentas de IA por conta própria para otimizar tarefas do dia a dia, sem seguir diretrizes ou aprovações internas. Essa prática coloca em risco segredos comerciais e dados estratégicos, já que as informações fornecidas a esses modelos podem ser armazenadas temporariamente ou processadas em servidores externos. De acordo com o relatório, o ChatGPT é responsável por 77% de todo o uso de IA generativa em ambientes corporativos, sendo a plataforma mais usada para redigir textos, revisar documentos e gerar relatórios. Outras soluções, como o Gemini do Google e o Copilot da Microsoft, também aparecem entre as mais populares, ampliando o desafio de controle e conformidade. Especialistas alertam que a falta de políticas claras de governança de IA e de soluções de Data Loss Prevention (DLP) cria brechas graves de segurança.</description><guid isPermaLink="true">https://boletimsec.com.br/boletim-diario-ciberseguranca/</guid></item></channel></rss>