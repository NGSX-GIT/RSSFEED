<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/"><channel><title>Boletim diário de segurança</title><link>https://boletimsec.com.br/boletim-diario-ciberseguranca/</link><description>NGSX RSS Feed</description><language>pt-BR</language><generator>rfeed v1.1.1</generator><docs>https://github.com/svpino/rfeed/blob/master/README.md</docs><item><title>* Nova ferramenta de IA facilita criação de malware e phishing.</title><link>https://boletimsec.com.br/boletim-diario-ciberseguranca/</link><description>Pesquisadores de cibersegurança identificaram uma nova ferramenta de inteligência artificial chamada GhostGPT, desenvolvida para facilitar atividades maliciosas como a criação de malware e campanhas de phishing. Essa ferramenta, que já está sendo comercializada em fóruns de cibercrime e no Telegram desde o final de 2024, representa uma ameaça crescente ao transformar inteligência artificial em um recurso acessível para criminosos. Segundo a pesquisa, o GhostGPT utiliza um wrapper que se conecta a uma versão desbloqueada do ChatGPT ou a outro modelo de linguagem de código aberto, permitindo respostas sem censura. Essa configuração oferece aos usuários criminosos a capacidade de conduzir campanhas sofisticadas, mesmo com pouco conhecimento técnico. A ferramenta segue os passos de outros modelos maliciosos, como o WormGPT, lançado em 2023 para auxiliar em ataques de compromisso de e-mail corporativo (BEC). Desde então, variantes como WolfGPT e EscapeGPT também surgiram, sinalizando uma tendência alarmante no uso de IA para fins criminosos. No caso do GhostGPT, o acesso é extremamente simples, sendo disponibilizado por meio de um bot no Telegram. Essa facilidade elimina a necessidade de desbloquear manualmente o ChatGPT ou configurar modelos alternativos, o que aumenta sua atratividade entre criminosos. Além disso, os desenvolvedores da ferramenta garantem que nenhuma atividade do usuário é registrada, protegendo a identidade de quem a utiliza para fins ilícitos. A popularidade do GhostGPT já é evidente, com milhares de visualizações em fóruns online, indicando um interesse crescente por parte dos cibercriminosos.</description><guid isPermaLink="true">https://boletimsec.com.br/boletim-diario-ciberseguranca/</guid></item><item><title>* Google lança Identity Check para reforçar a segurança de dispositivos Android.</title><link>https://boletimsec.com.br/boletim-diario-ciberseguranca/</link><description>O Google anunciou o lançamento de um novo recurso de segurança chamado Identity Check, projetado para dispositivos Android compatíveis. Essa funcionalidade adiciona uma camada extra de proteção, exigindo autenticação biométrica para acessar configurações sensíveis do sistema quando o dispositivo está fora de locais considerados confiáveis. A medida tem como objetivo reforçar a segurança contra acessos não autorizados e ataques, protegendo dados e configurações importantes. De acordo com o Google, o Identity Check bloqueia ações críticas, como o acesso a senhas salvas no Google Password Manager, a alteração de bloqueios de tela (PIN, padrão ou senha) e de configurações de biometria, além de proteger contra a desativação de recursos como o “Find My Device” ou a realização de um reset de fábrica. O recurso também dificulta o uso de ferramentas avançadas, como opções de desenvolvedor, sem a devida autenticação, garantindo que somente o proprietário do dispositivo possa realizar essas mudanças. Esse recurso está inicialmente disponível para smartphones Pixel com Android 15 e para alguns modelos da Samsung com One UI 7. Para ativá-lo, os usuários devem acessar o menu de configurações do sistema, na seção de proteção contra roubo. Além disso, o Identity Check oferece proteção aprimorada para contas Google associadas ao dispositivo, impedindo que pessoas não autorizadas assumam o controle dessas contas, mesmo que o aparelho esteja comprometido. O lançamento do Identity Check acompanha outros esforços recentes do Google para melhorar a segurança de dispositivos Android. A empresa expandiu a funcionalidade do Theft Detection Lock, que agora está disponível globalmente para dispositivos Android 10 ou superior, ajudando a proteger os aparelhos mesmo quando estão offline. O Google também reforçou sua parceria com a GSMA e especialistas da indústria para criar ferramentas e estratégias que combatam o roubo de dispositivos móveis.</description><guid isPermaLink="true">https://boletimsec.com.br/boletim-diario-ciberseguranca/</guid></item><item><title>* Falha em Framework da Meta expõe IA a riscos de execução remota de código.</title><link>https://boletimsec.com.br/boletim-diario-ciberseguranca/</link><description>Uma grave vulnerabilidade foi descoberta no framework de modelos de linguagem grande (LLM) da Meta, conhecido como Llama, que pode permitir que atacantes executem código arbitrário em servidores de inferência do Llama Stack. De acordo com o pesquisador Avi Lumelsky, o problema reside na desserialização de dados não confiáveis na API de inferência em Python usada pelo Llama Stack. Esse componente do framework oferece interfaces de API para desenvolvimento de aplicações de inteligência artificial, incluindo modelos próprios da Meta, e utiliza o módulo Python pickle para desserializar objetos. No entanto, esse formato é conhecido por permitir a execução de código arbitrário quando dados maliciosos são processados. A Meta foi informada da vulnerabilidade em 24 de setembro de 2024, e o problema foi corrigido na versão 0.0.41 do framework, lançada em 10 de outubro. Para mitigar o risco, a empresa substituiu o uso do formato pickle pelo mais seguro formato JSON para comunicação via socket. O problema também foi resolvido na biblioteca pyzmq, que fornece acesso à biblioteca de mensagens ZeroMQ. Essa falha reflete um padrão crescente de vulnerabilidades relacionadas à desserialização em frameworks de inteligência artificial. Em agosto de 2024, uma vulnerabilidade semelhante foi descoberta no framework TensorFlow Keras, permitindo execução arbitrária de código devido ao uso do módulo marshal, considerado inseguro. A descoberta de problemas como esses ressalta a importância de práticas seguras de desenvolvimento, especialmente em aplicações críticas como inteligência artificial.</description><guid isPermaLink="true">https://boletimsec.com.br/boletim-diario-ciberseguranca/</guid></item></channel></rss>