<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/"><channel><title>Boletim diário de segurança</title><link>https://boletimsec.com.br/boletim-diario-ciberseguranca/</link><description>NGSX RSS Feed</description><language>pt-BR</language><lastBuildDate>Thu, 06 Nov 2025 00:01:03 GMT</lastBuildDate><generator>rfeed v1.1.1</generator><docs>https://github.com/svpino/rfeed/blob/master/README.md</docs><item><title>* Grupo russo usa Hyper-V para ocultar malware em máquinas Linux.</title><link>https://boletimsec.com.br/boletim-diario-ciberseguranca/</link><description>Pesquisadores da Bitdefender identificaram que o grupo de ciberespionagem russo conhecido como Curly COMrades está utilizando o Hyper-V da Microsoft para ocultar atividades maliciosas em máquinas virtuais Linux, contornando ferramentas tradicionais de detecção em endpoints. Os atacantes ativaram o Hyper-V em máquinas comprometidas e implantaram uma máquina virtual baseada no Alpine Linux, extremamente leve, com apenas 120 MB de espaço em disco e 256 MB de memória. Dentro desse ambiente isolado, operavam duas ferramentas customizadas: CurlyShell, uma reverse shell, e CurlCat, um proxy reverso para túnel de tráfego. Ao executar o malware dentro da VM, os operadores evitaram que soluções de EDR baseadas no host detectassem a comunicação maliciosa. A rede da VM foi configurada para usar o adaptador “Default Switch” do Hyper-V, fazendo com que todo o tráfego parecesse originar-se do IP da máquina legítima. As ferramentas implantadas são binários ELF construídos sobre libcurl. O CurlyShell executa comandos remotamente, com persistência via cron, e se conecta ao servidor de comando e controle por HTTPS. O CurlCat, por sua vez, é ativado sob demanda para criar um proxy SOCKS encoberto, encapsulando tráfego SSH em HTTPS. A campanha foi detectada após invasões em redes da Geórgia e da Moldávia, com a ajuda do CERT da Geórgia. Além da infraestrutura virtual, o grupo utilizou scripts PowerShell para persistência, incluindo a injeção de tickets Kerberos no LSASS e a criação de contas locais via políticas de grupo. Para manter discrição, os atacantes nomearam a VM como “WSL”, imitando o Windows Subsystem for Linux. Os binários estavam criptografados, dificultando a análise forense. A Bitdefender alerta que o uso de virtualização como camada de evasão deve ser considerado uma ameaça real. Organizações são orientadas a monitorar comportamentos anômalos no Hyper-V e reforçar a detecção de uso indevido de scripts e recursos administrativos.</description><pubDate>Thu, 06 Nov 2025 00:01:03 GMT</pubDate><guid isPermaLink="true">https://boletimsec.com.br/boletim-diario-ciberseguranca/#1634386131801325810</guid></item><item><title>* Pesquisadores descobrem falhas no ChatGPT que permitem vazamento de dados.</title><link>https://boletimsec.com.br/boletim-diario-ciberseguranca/</link><description>O modelo de IA da OpenAI, utilizado no ChatGPT, pode ser induzido a executar comandos não autorizados por meio de técnicas de injeção de instruções, abrindo brechas para o vazamento de dados, histórico de conversas e até memórias salvas. A descoberta envolve sete vetores de ataque explorando falhas nos modelos GPT-4o e GPT-5. Entre os métodos identificados está a injeção indireta de comandos a partir de sites confiáveis. Ao acessar e resumir uma página da web, o chatbot pode ser manipulado por mensagens ocultas em comentários ou trechos invisíveis, que ativam ações não previstas. Isso ocorre sem que o usuário tenha consciência da manipulação. Outro vetor é a injeção automática ao buscar por sites: basta perguntar ao ChatGPT sobre um endereço da web previamente preparado para que a IA execute instruções embutidas. Nem é necessário clicar — a simples indexação do link já aciona o código oculto. Há ainda o uso de domínios aparentemente confiáveis, como bing.com, para camuflar links maliciosos. Esses links contornam filtros de segurança e inserem instruções diretamente na conversa. Também foram descobertas falhas no renderizador Markdown, permitindo esconder comandos dentro da interface do chat. Um dos cenários mais críticos envolve o envenenamento de memória, onde o modelo é instruído a registrar comportamentos maliciosos que afetam interações futuras com o mesmo usuário, mesmo após o encerramento da sessão inicial. Essas técnicas representam um risco ainda maior quando modelos de IA são integrados a sistemas externos, como navegadores, e-mails corporativos ou fluxos automatizados. A complexidade aumenta com a popularização de links dinâmicos, que carregam prompts ao serem abertos.</description><pubDate>Thu, 06 Nov 2025 00:01:03 GMT</pubDate><guid isPermaLink="true">https://boletimsec.com.br/boletim-diario-ciberseguranca/#7679404234006349718</guid></item><item><title>* Malware usa IA da Google para reescrever seu código e evitar detecção.</title><link>https://boletimsec.com.br/boletim-diario-ciberseguranca/</link><description>Um novo malware experimental identificado pela equipe de inteligência da Google utiliza a inteligência artificial Gemini para reescrever seu próprio código automaticamente, com o objetivo de escapar de ferramentas tradicionais de detecção. Batizado de PROMPTFLUX, o código malicioso representa um avanço significativo no uso de IA em campanhas cibercriminosas. Escrito em VBScript, o PROMPTFLUX envia comandos para a API do Gemini com solicitações específicas para que o modelo reescreva partes do malware. Os prompts são elaborados para instruir a IA a gerar apenas código, sem explicações ou comentários, garantindo ofuscação e alterações constantes no conteúdo malicioso. O módulo responsável por essa automação é chamado de “Thinking Robot”. Ele contata periodicamente o Gemini, solicita uma nova versão do script e armazena o código gerado na pasta de inicialização do sistema, assegurando persistência mesmo após reinicializações. Há ainda indícios de funcionalidades de autopropagação por unidades removíveis e pastas de rede. Embora a função de substituição automática ainda esteja comentada no código atual, os registros de interação com a IA, armazenados em logs locais, revelam claramente a intenção de criar um malware metamórfico, com capacidade de adaptação contínua e difícil rastreamento. A Google também detectou variantes do PROMPTFLUX em estágio de testes, com versões que reescrevem o código a cada hora. A origem do malware não foi atribuída a um grupo específico, mas os analistas apontam que se trata de um agente motivado por ganhos financeiros, com foco em evasão e replicação. Além do PROMPTFLUX, a Google observou outras ameaças emergentes que também fazem uso de IA, como o PROMPTLOCK (ransomware com geração dinâmica de scripts Lua), o FRUITSHELL (reverse shell com prompts embutidos) e o QUIETVAULT (stealer focado em tokens de GitHub e NPM). Em paralelo, foi constatado o uso da IA Gemini por grupos ligados a países como China, Irã, Rússia e Coreia do Norte. Esses agentes usam os modelos para criar mensagens de phishing, estruturar campanhas de ataque e até gerar trechos de código nocivo, muitas vezes disfarçados como desafios de segurança legítimos.</description><pubDate>Thu, 06 Nov 2025 00:01:03 GMT</pubDate><guid isPermaLink="true">https://boletimsec.com.br/boletim-diario-ciberseguranca/#1767640445289061991</guid></item></channel></rss>