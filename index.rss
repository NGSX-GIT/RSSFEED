<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/"><channel><title>Boletim diário de segurança</title><link>https://boletimsec.com.br/boletim-diario-ciberseguranca/</link><description>NGSX RSS Feed</description><language>pt-BR</language><generator>rfeed v1.1.1</generator><docs>https://github.com/svpino/rfeed/blob/master/README.md</docs><item><title>* Hackers Usam PDFs para Enganar Usuários com Suporte Falso da Microsoft e DocuSign.</title><link>https://boletimsec.com.br/boletim-diario-ciberseguranca/</link><description>Campanhas de phishing estão explorando arquivos PDF para enganar usuários e levá-los a ligar para números controlados por criminosos. Esse tipo de ataque, chamado TOAD (Telephone-Oriented Attack Delivery), envolve o envio de e-mails com PDFs que simulam marcas confiáveis como Microsoft, DocuSign, Norton, PayPal e Geek Squad. De 5 de maio a 5 de junho de 2025, a Cisco Talos detectou diversas campanhas que usam PDFs com logotipos legítimos e QR codes maliciosos que redirecionam para páginas falsas de login, muitas vezes simulando serviços como Dropbox ou Microsoft 365. Alguns anexos contêm URLs ocultas em anotações ou formulários dentro dos PDFs, aumentando a credibilidade do golpe. Nos ataques TOAD, a vítima é induzida a ligar para um número “suporte técnico” para resolver um problema falso. Do outro lado da linha, os criminosos usam técnicas de engenharia social, vozes simulando atendentes reais e até música de espera para convencer a vítima a fornecer dados confidenciais ou instalar malwares. Esses ataques têm sido usados para espalhar trojans bancários e softwares de acesso remoto, permitindo controle total sobre os dispositivos das vítimas. O FBI alertou recentemente sobre o grupo Luna Moth, que usa essa tática se passando por departamentos de TI. Além disso, campanhas recentes abusam da função “Direct Send” do Microsoft 365 para enviar e-mails falsos que parecem internos, dificultando sua detecção. Outros golpes envolvem manipulação de resultados de busca com sites comprometidos (.gov ou .edu) que redirecionam para páginas de phishing, além do uso de IA para criar URLs enganosas ou APIs maliciosas em plataformas como o GitHub.</description><guid isPermaLink="true">https://boletimsec.com.br/boletim-diario-ciberseguranca/</guid></item><item><title>* Ferramenta de IA é Usada para Criação de Sites Falsos para Golpes Online.</title><link>https://boletimsec.com.br/boletim-diario-ciberseguranca/</link><description>Criminosos estão usando uma ferramenta de inteligência artificial chamada v0 para criar páginas falsas de login que imitam sites legítimos com aparência profissional. A ferramenta permite gerar essas páginas a partir de simples comandos de texto, sem exigir conhecimento técnico ou programação, o que torna o golpe acessível até para golpistas iniciantes. Originalmente projetada para facilitar o desenvolvimento de sites, a plataforma passou a ser explorada por golpistas que conseguem criar páginas de acesso falso em poucos minutos. Algumas dessas páginas já imitavam sistemas de login de empresas conhecidas. Após denúncias, os sites falsos e os recursos hospedados, como logotipos oficiais, foram removidos da plataforma. O uso dessa ferramenta marca uma nova fase no avanço dos golpes com apoio de inteligência artificial. Ao contrário dos kits tradicionais de phishing, que exigem mais preparo técnico, essas ferramentas aceleram e ampliam os ataques. Os criminosos não apenas constroem sites falsos com facilidade, como também se aproveitam da reputação da plataforma onde hospedam os conteúdos, dificultando a detecção por sistemas de segurança. Além disso, está crescendo o uso de modelos de inteligência artificial sem filtros de segurança, que respondem a comandos perigosos e ajudam a elaborar golpes mais sofisticados. Golpistas já utilizam esses sistemas para criar e-mails falsos, clonar vozes e até gerar vídeos com rostos e falas simuladas, ampliando a escala e o impacto das fraudes digitais. Esse cenário mostra que os golpes online estão deixando de ser ações isoladas para se tornarem operações automatizadas e cada vez mais realistas, impulsionadas por inteligência artificial.</description><guid isPermaLink="true">https://boletimsec.com.br/boletim-diario-ciberseguranca/</guid></item><item><title>* Pesquisadores Criam Técnica que Engana Visão de Inteligência Artificial.</title><link>https://boletimsec.com.br/boletim-diario-ciberseguranca/</link><description>Pesquisadores desenvolveram uma nova técnica de ataque que permite manipular o que sistemas de inteligência artificial enxergam em imagens. A técnica, chamada RisingAttack, afeta diretamente modelos de visão computacional, inclusive os mais populares e amplamente utilizados atualmente. O ataque é do tipo adversarial, ou seja, pequenas alterações são inseridas em uma imagem de forma quase imperceptível ao olho humano, mas suficientes para enganar completamente a IA. Com isso, um sistema pode deixar de reconhecer sinais de trânsito, pedestres ou veículos, o que representa sérios riscos em contextos como veículos autônomos, exames médicos por imagem e sistemas de segurança. De acordo com o estudo, a RisingAttack supera técnicas anteriores ao apresentar maior taxa de sucesso com menos alterações na imagem original. O processo começa com a identificação de todos os elementos visuais da imagem e determina quais são mais relevantes para o objetivo do ataque. Em seguida, o sistema calcula a sensibilidade da IA a essas mudanças e aplica alterações mínimas, mas eficazes, nos pontos mais sensíveis. Na prática, isso significa que duas imagens idênticas para um ser humano podem ter interpretações completamente diferentes para um sistema de IA. Em uma, o carro é identificado normalmente; na outra, o carro desaparece da análise da máquina. Segundo os pesquisadores, essa descoberta alerta para a necessidade de reforçar a segurança desses sistemas, já que muitos deles são usados em áreas onde a vida humana pode estar em risco.</description><guid isPermaLink="true">https://boletimsec.com.br/boletim-diario-ciberseguranca/</guid></item></channel></rss>